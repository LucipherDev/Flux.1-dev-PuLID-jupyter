{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucipherDev/Flux.1-dev-PuLID-jupyter/blob/main/Flux.1-dev-PuLID-jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Install</h1></center>\n",
        "\n",
        "%cd /content\n",
        "!git clone -b totoro6 https://github.com/LucipherDev/ComfyUI /content/TotoroUI\n",
        "!git clone -b totoro https://github.com/LucipherDev/ComfyUI-GGUF /content/TotoroUI/custom_nodes/TotoroUI-GGUF\n",
        "!git clone -b totoro https://github.com/LucipherDev/ComfyUI-PuLID-Flux /content/TotoroUI/custom_nodes/TotoroUI-PuLID-Flux\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.28.post2\n",
        "!pip install -q -r /content/TotoroUI/custom_nodes/TotoroUI-GGUF/requirements.txt\n",
        "!pip install -q -r /content/TotoroUI/custom_nodes/TotoroUI-PuLID-Flux/requirements.txt\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "import nodes\n",
        "\n",
        "if not nodes.load_custom_node(\"custom_nodes/TotoroUI-GGUF\"):\n",
        "  raise Exception(\"Failed to load GGUF custom node\")\n",
        "\n",
        "if not nodes.load_custom_node(\"custom_nodes/TotoroUI-PuLID-Flux\"):\n",
        "  raise Exception(\"Failed to load PuLID Flux Enhanced custom node\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3aTOrdb8HxC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Load Models</h1></center>\n",
        "\n",
        "import torch\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "DualCLIPLoaderGGUF = NODE_CLASS_MAPPINGS[\"DualCLIPLoaderGGUF\"]()\n",
        "UnetLoaderGGUF = NODE_CLASS_MAPPINGS[\"UnetLoaderGGUF\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "PulidFluxModelLoader = NODE_CLASS_MAPPINGS[\"PulidFluxModelLoader\"]()\n",
        "PulidFluxInsightFaceLoader = NODE_CLASS_MAPPINGS[\"PulidFluxInsightFaceLoader\"]()\n",
        "PulidFluxEvaClipLoader = NODE_CLASS_MAPPINGS[\"PulidFluxEvaClipLoader\"]()\n",
        "\n",
        "print(f\"Downloading Flux1-dev-Q4_K_S...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf -d /content/TotoroUI/models/unet -o flux1-dev-Q4_K_S.gguf\n",
        "\n",
        "print(\"Downloading VAE...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
        "\n",
        "print(\"Downloading Clips...\")\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q6_K.gguf -d /content/TotoroUI/models/clip -o t5-v1_1-xxl-encoder-Q6_K.gguf\n",
        "\n",
        "print(\"Downloading PuLID...\")\n",
        "\n",
        "pulid_version = \"v0.9.1\" # @param [\"v0.9.0\",\"v0.9.1\"]\n",
        "\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/guozinan/PuLID/resolve/main/pulid_flux_{pulid_version}.safetensors -d /content/TotoroUI/models/pulid -o pulid_flux_{pulid_version}.safetensors\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://github.com/deepinsight/insightface/releases/download/v0.7/antelopev2.zip -d /content/TotoroUI/models/insightface/models -o antelopev2.zip\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth -d /usr/local/lib/python3.10/dist-packages/facexlib/weights -o detection_Resnet50_Final.pth\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth -d /usr/local/lib/python3.10/dist-packages/facexlib/weights -o parsing_parsenet.pth\n",
        "!aria2c --quiet --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://github.com/xinntao/facexlib/releases/download/v0.2.0/parsing_bisenet.pth -d /usr/local/lib/python3.10/dist-packages/facexlib/weights -o parsing_bisenet.pth\n",
        "!unzip -q /content/TotoroUI/models/insightface/models/antelopev2.zip -d /content/TotoroUI/models/insightface/models/\n",
        "\n",
        "with torch.inference_mode():\n",
        "    eva_clip = PulidFluxEvaClipLoader.load_eva_clip()[0]\n",
        "    print(\"Loading VAE...\")\n",
        "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "    print(f\"Loading Flux1-dev-Q4_K_S...\")\n",
        "    unet = UnetLoaderGGUF.load_unet(f\"flux1-dev-Q4_K_S.gguf\")[0]\n",
        "    print(\"Loading Clips...\")\n",
        "    clip = DualCLIPLoaderGGUF.load_clip(\"t5-v1_1-xxl-encoder-Q6_K.gguf\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "    print(\"Loading PuLID...\")\n",
        "    pulid = PulidFluxModelLoader.load_model(f\"pulid_flux_{pulid_version}.safetensors\")[0]\n",
        "    face_analysis = PulidFluxInsightFaceLoader.load_insightface(\"CPU\")[0]\n",
        "\n",
        "    unet_f, clip_f = unet, clip\n",
        "\n",
        "print(\"All Models Loaded!\")\n",
        "\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab import files, output\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image, ImageOps\n",
        "import io\n",
        "import base64\n",
        "\n",
        "import nodes\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_post_processing\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro_extras import nodes_mask\n",
        "from totoro import model_management\n",
        "\n",
        "CLIPTextEncodeFlux = nodes_flux.NODE_CLASS_MAPPINGS[\"CLIPTextEncodeFlux\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "MaskToImage = nodes_mask.NODE_CLASS_MAPPINGS[\"MaskToImage\"]()\n",
        "ImageToMask = nodes_mask.NODE_CLASS_MAPPINGS[\"ImageToMask\"]()\n",
        "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "ImageScaleToTotalPixels = nodes_post_processing.NODE_CLASS_MAPPINGS[\"ImageScaleToTotalPixels\"]()\n",
        "ApplyPulidFlux = NODE_CLASS_MAPPINGS[\"ApplyPulidFlux\"]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLGPKWvopwnC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown <center><h1>Functions</h1></center>\n",
        "\n",
        "# @markdown <ul><li><h2>Load PuLID</h2></li></ul>\n",
        "\n",
        "pulid_input_image = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "use_attention_mask = True # @param {\"type\":\"boolean\"}\n",
        "use_mask_from_image = False # @param {\"type\":\"boolean\"}\n",
        "mask_dir = \"/content/inpaint_mask.png\" # @param {\"type\":\"string\"}\n",
        "draw_mask = True # @param {\"type\":\"boolean\"}\n",
        "invert_mask = False\n",
        "\n",
        "paint_interface = f\"\"\"\n",
        "<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css');body{{background-color:#2d2d2d;font-family:Arial,sans-serif;color:#fff;margin:0;display:flex;justify-content:center;align-items:center}}#toolbar{{display:flex;flex-wrap:wrap;justify-content:center;align-items:center;padding:10px 0;margin:10px auto;background-color:#3c3f41;border-radius:8px;width:100%;max-width:512px;box-shadow:0 4px 10px rgba(0,0,0,0.3)}}.button{{padding:10px 15px;margin:5px;font-size:14px;cursor:pointer;border-radius:5px;color:#fff;background-color:#5e5e5e;border:0;font-weight:bold;transition:.3s}}.button:hover{{background-color:#757575}}.button.active{{background-color:#fff7e0;color:#202124}}.button:disabled{{cursor:default;background-color:#a9a9a9}}.slider-container{{display:flex;align-items:center;margin:10px 0}}#brushSizeSlider{{margin-left:10px;cursor:pointer;width:200px}}#canvasContainer{{margin:20px auto;border:2px solid #5e5e5e;border-radius:8px;position:relative;display:inline-block;width:512px;height:512px}}canvas{{display:block;cursor:crosshair}}#imageOverlay{{position:absolute;top:0;left:0;pointer-events:none;opacity:.5;z-index:0}}</style>\n",
        "<div id=\"toolbar\">\n",
        "<button class=\"button active\" id=\"drawButton\" onclick=\"setTool('draw')\"><i class=\"fa fa-paint-brush\"></i> Draw</button>\n",
        "<button class=\"button\" id=\"eraseButton\" onclick=\"setTool('erase')\"><i class=\"fa fa-eraser\"></i> Erase</button>\n",
        "<button class=\"button\" id=\"clearButton\" onclick=\"clearCanvas()\"><i class=\"fa fa-trash\"></i> Clear</button>\n",
        "<button class=\"button\" id=\"saveButton\" onclick=\"saveCanvas()\"><i class=\"fa fa-check\"></i> Save</button>\n",
        "<button class=\"button\" id=\"undoButton\" onclick=\"undo()\" disabled><i class=\"fa fa-undo\"></i></button>\n",
        "<button class=\"button\" id=\"redoButton\" onclick=\"redo()\" disabled><i class=\"fa fa-rotate-right\"></i></button>\n",
        "<div class=\"slider-container\">\n",
        "<label for=\"brushSizeSlider\">Brush Size: <span id=\"brushSizeDisplay\">20</span></label>\n",
        "<input id=\"brushSizeSlider\" type=\"range\" min=\"1\" max=\"100\" value=\"20\">\n",
        "</div>\n",
        "</div>\n",
        "<div id=\"canvasContainer\">\n",
        "<img id=\"imageOverlay\" />\n",
        "<canvas id=\"paintCanvas\"></canvas>\n",
        "</div>\n",
        "<script>const canvas=document.getElementById('paintCanvas');const ctx=canvas.getContext('2d');const imageOverlay=document.getElementById('imageOverlay');const canvasContainer=document.getElementById('canvasContainer');const brushSizeSlider=document.getElementById('brushSizeSlider');const brushSizeDisplay=document.getElementById('brushSizeDisplay');let tool='draw';let drawing=false;let brushSize=20;function highlightActiveButton(tool){{document.querySelectorAll('.button').forEach(button=>button.classList.remove('active'));if(tool==='draw'){{document.getElementById('drawButton').classList.add('active');}}else if(tool==='erase'){{document.getElementById('eraseButton').classList.add('active');}}}}\n",
        "const backgroundImage=new Image();backgroundImage.src=\"/files/{pulid_input_image}\";backgroundImage.onload=function(){{const aspectRatio=backgroundImage.width/backgroundImage.height;let width,height;if(backgroundImage.width>backgroundImage.height){{height=512;width=height*aspectRatio;}}else{{width=512;height=width/aspectRatio;}}\n",
        "canvas.width=width;canvas.height=height;imageOverlay.width=width;imageOverlay.height=height;canvasContainer.style.width=`${{width}}px`;canvasContainer.style.height=`${{height}}px`;ctx.fillStyle='{'white' if invert_mask else 'black'}';ctx.fillRect(0,0,canvas.width,canvas.height);imageOverlay.src=backgroundImage.src;}};brushSizeSlider.addEventListener('input',function(event){{brushSize=event.target.value;brushSizeDisplay.textContent=brushSize;}});function setTool(selectedTool){{tool=selectedTool;highlightActiveButton(tool);}}\n",
        "canvas.addEventListener('mousedown',()=>{{drawing=true;}});canvas.addEventListener('mouseup',()=>{{drawing=false;ctx.beginPath();}});canvas.addEventListener('mousemove',draw);function draw(event){{if(!drawing)return;const rect=canvas.getBoundingClientRect();const x=event.clientX-rect.left;const y=event.clientY-rect.top;ctx.lineWidth=brushSize;ctx.lineCap='round';ctx.globalCompositeOperation='source-over';if(tool==='draw'){{ctx.strokeStyle='{'black' if invert_mask else 'white'}';}}else if(tool==='erase'){{ctx.strokeStyle='{'white' if invert_mask else 'black'}';}}\n",
        "ctx.lineTo(x,y);ctx.stroke();ctx.beginPath();ctx.moveTo(x,y);}}\n",
        "function clearCanvas(){{ctx.globalCompositeOperation='source-over';ctx.fillStyle='{'white' if invert_mask else 'black'}';ctx.fillRect(0,0,canvas.width,canvas.height);ctx.beginPath();}}\n",
        "function saveCanvas(){{const dataURL=canvas.toDataURL('image/png');google.colab.kernel.invokeFunction('notebook.save_mask',[dataURL],{{}});}}\n",
        "const undoStack=[];const redoStack=[];function updateUndoRedoButtons(){{document.getElementById('undoButton').disabled=undoStack.length===0;document.getElementById('redoButton').disabled=redoStack.length===0;}}\n",
        "function saveState(){{undoStack.push(canvas.toDataURL());redoStack.length=0;updateUndoRedoButtons();}}\n",
        "function undo(){{if(undoStack.length===0)return;redoStack.push(canvas.toDataURL());const previousState=undoStack.pop();const img=new Image();img.src=previousState;img.onload=function(){{ctx.clearRect(0,0,canvas.width,canvas.height);ctx.drawImage(img,0,0);}};updateUndoRedoButtons();}}\n",
        "function redo(){{if(redoStack.length===0)return;undoStack.push(canvas.toDataURL());const nextState=redoStack.pop();const img=new Image();img.src=nextState;img.onload=function(){{ctx.clearRect(0,0,canvas.width,canvas.height);ctx.drawImage(img,0,0);}};updateUndoRedoButtons();}}\n",
        "canvas.addEventListener('mousedown',()=>{{saveState();drawing=true;}});canvas.addEventListener('mouseup',()=>{{drawing=false;ctx.beginPath();}});updateUndoRedoButtons();</script>\n",
        "\"\"\"\n",
        "\n",
        "def save_mask(data_url):\n",
        "  global mask_dir\n",
        "\n",
        "  header, encoded = data_url.split(\",\", 1)\n",
        "  binary_data = base64.b64decode(encoded)\n",
        "  img = Image.open(io.BytesIO(binary_data))\n",
        "  mask_dir = f\"/content/inpaint_mask_{''.join(str(random.randint(0, 9)) for _ in range(5))}.png\"\n",
        "  img.save(mask_dir)\n",
        "\n",
        "  print(f\"Mask saved: {mask_dir}\")\n",
        "\n",
        "def img_tensor_to_np(img_tensor):\n",
        "  img_tensor = img_tensor.clone() * 255.0\n",
        "  return img_tensor.squeeze().numpy().astype(np.uint8)\n",
        "\n",
        "def img_np_to_tensor(img_np_list):\n",
        "  return torch.from_numpy(img_np_list.astype(np.float32) / 255.0).unsqueeze(0)\n",
        "\n",
        "def cuda_gc():\n",
        "  try:\n",
        "    model_management.soft_empty_cache()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "def save_image(decoded, path, name, download=False):\n",
        "  full_path = os.path.abspath(os.path.join(path, name))\n",
        "  Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save( full_path)\n",
        "\n",
        "  img = Image.open(full_path)\n",
        "  display(img)\n",
        "\n",
        "  if download:\n",
        "    files.download(full_path)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(prompt, width, height, fixed_seed, guidance, steps, sampler_name, scheduler, weight, start_at, end_at, batch_size, auto_download, mode=\"t2i\", input_img=None, denoise=1.0):\n",
        "  global unet, clip, unet_f, clip_f\n",
        "\n",
        "  unet_f, clip_f = unet, clip\n",
        "\n",
        "  print(\"Prompt Received\")\n",
        "\n",
        "  if mode == \"t2i\":\n",
        "    latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
        "\n",
        "  elif mode == \"i2i\":\n",
        "    image = LoadImage.load_image(input_img)[0]\n",
        "    latent_image = ImageScaleToTotalPixels.upscale(image, \"lanczos\", 1.0)[0]\n",
        "    latent_image = VAEEncode.encode(vae, latent_image)[0]\n",
        "\n",
        "  cond = CLIPTextEncodeFlux.encode(clip_f, prompt, prompt, guidance)[0]\n",
        "\n",
        "  pulid_image, mask = LoadImage.load_image(pulid_input_image)\n",
        "  image_np = img_tensor_to_np(pulid_image)\n",
        "  img = Image.fromarray(image_np)\n",
        "\n",
        "  if use_attention_mask:\n",
        "    if not use_mask_from_image:\n",
        "      mask_image = LoadImage.load_image(mask_dir)[0]\n",
        "      mask_np = img_tensor_to_np(mask_image)\n",
        "      mask_img = Image.fromarray(mask_np)\n",
        "      mask_img = mask_img.resize((img.width, img.height), Image.Resampling.LANCZOS)\n",
        "      mask_np = np.array(mask_img).astype(np.uint8)\n",
        "      mask_image = img_np_to_tensor(mask_np)\n",
        "\n",
        "      mask = ImageToMask.image_to_mask(mask_image, \"red\")[0]\n",
        "\n",
        "  else:\n",
        "    mask = None\n",
        "\n",
        "  if use_attention_mask:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"display: flex; gap: 10px;\">\n",
        "        {\"\".join(f'<img src=\"data:image/png;base64,{base64.b64encode(io.BytesIO(Image.fromarray(img).save((buf:=io.BytesIO()), format=\"PNG\") or buf.getvalue()).getvalue()).decode(\"utf-8\")}\" style=\"width: 512px;\">' for img in [img_tensor_to_np(pulid_image), img_tensor_to_np(MaskToImage.mask_to_image(mask)[0])])}\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "  else:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"display: flex; gap: 10px;\">\n",
        "        <img src=\"data:image/png;base64,{base64.b64encode(io.BytesIO(img.save((buf:=io.BytesIO()), format=\"PNG\") or buf.getvalue()).getvalue()).decode(\"utf-8\")}\" style=\"width: 512px;\">\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "  unet_f = ApplyPulidFlux.apply_pulid_flux(unet_f, pulid, eva_clip, face_analysis, pulid_image, weight, start_at, end_at, attn_mask=mask)[0]\n",
        "\n",
        "  print(\"PuLID Applied\")\n",
        "\n",
        "  guider = BasicGuider.get_guider(unet_f, cond)[0]\n",
        "  sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "  sigmas = BasicScheduler.get_sigmas(unet_f, scheduler, steps, denoise)[0]\n",
        "\n",
        "  for i in range(0, batch_size):\n",
        "    if fixed_seed == 0:\n",
        "      seed = random.randint(0, 18446744073709551615)\n",
        "    else:\n",
        "      seed = fixed_seed\n",
        "\n",
        "    print(\"Seed:\", seed)\n",
        "\n",
        "    noise = RandomNoise.get_noise(seed)[0]\n",
        "    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "    model_management.soft_empty_cache()\n",
        "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "\n",
        "    save_image(decoded, \"/content\", f\"flux_{mode}_{seed}_{i}.png\", auto_download)\n",
        "\n",
        "  del unet_f\n",
        "  del clip_f\n",
        "  cuda_gc()\n",
        "\n",
        "if draw_mask:\n",
        "  print(\"\\n\\n\\n\")\n",
        "  output.register_callback('notebook.save_mask', save_mask)\n",
        "  display(HTML(paint_interface))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ur9TmMNwC2kR"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Txt2Img</h1></center>\n",
        "\n",
        "positive_prompt = \"\" # @param {\"type\":\"string\"}\n",
        "width = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "height = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "guidance = 3.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.5}\n",
        "steps = 20 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "pulid_weight = 1 # @param {\"type\":\"slider\",\"min\":-1,\"max\":5,\"step\":0.05}\n",
        "pulid_start_at = 0.015 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.001}\n",
        "pulid_end_at = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.001}\n",
        "batch_size = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "generate(positive_prompt, width, height, fixed_seed, guidance, steps, sampler_name, scheduler, pulid_weight, pulid_start_at, pulid_end_at, batch_size, auto_download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dpd2sfrePYoA"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Img2Img</h1></center>\n",
        "\n",
        "positive_prompt = \"\" # @param {\"type\":\"string\"}\n",
        "fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "guidance = 3.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.5}\n",
        "steps = 20 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "input_img = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "denoise = 0.75 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "pulid_weight = 1 # @param {\"type\":\"slider\",\"min\":-1,\"max\":5,\"step\":0.05}\n",
        "pulid_start_at = 0.015 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.001}\n",
        "pulid_end_at = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.001}\n",
        "batch_size = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "generate(positive_prompt, 0, 0, fixed_seed, guidance, steps, sampler_name, scheduler, pulid_weight, pulid_start_at, pulid_end_at, batch_size, auto_download, \"i2i\", input_img, denoise)"
      ]
    }
  ]
}